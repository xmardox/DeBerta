WARNING:tensorflow:From C:\Users\lapla\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

WARNING:tensorflow:From C:\Users\lapla\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\tf_keras\src\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

All model checkpoint layers were used when initializing TFDebertaModel.

All the layers of TFDebertaModel were initialized from the model checkpoint at microsoft/deberta-base.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaModel for predictions without further training.
Using cache file path: cache\CSE_CIC_IDS_1300_QdLmZHuh8yOmlGcKBEkf7hepImY0_9Xii0x0FeiUOoDMwEgiWksBPgKc0.feather
Reading directly from cache cache\CSE_CIC_IDS_1300_QdLmZHuh8yOmlGcKBEkf7hepImY0_9Xii0x0FeiUOoDMwEgiWksBPgKc0.feather...
No se encontró la columna 'text'. Generando a partir de las demás columnas desde cache...
Tokenizando la columna 'text' para crear input_ids y attention_mask...
All model checkpoint layers were used when initializing TFDebertaModel.

All the layers of TFDebertaModel were initialized from the model checkpoint at microsoft/deberta-base.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaModel for predictions without further training.
WARNING:tensorflow:From C:\Users\lapla\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\keras\src\backend\tensorflow\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.
[1mModel: "functional"[0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m [0m[1mLayer (type)                 [0m[1m [0m┃[1m [0m[1mOutput Shape             [0m[1m [0m┃[1m [0m[1m        Param #[0m[1m [0m┃[1m [0m[1mConnected to              [0m[1m [0m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_ids ([38;5;33mInputLayer[0m)        │ ([38;5;45mNone[0m, [38;5;34m128[0m)               │               [38;5;34m0[0m │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ attention_mask ([38;5;33mInputLayer[0m)   │ ([38;5;45mNone[0m, [38;5;34m128[0m)               │               [38;5;34m0[0m │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ deberta ([38;5;33mLambda[0m)              │ ([38;5;45mNone[0m, [38;5;34m768[0m)               │               [38;5;34m0[0m │ input_ids[[38;5;34m0[0m][[38;5;34m0[0m],           │
│                               │                           │                 │ attention_mask[[38;5;34m0[0m][[38;5;34m0[0m]       │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ slice_last ([38;5;33mLambda[0m)           │ ([38;5;34m768[0m)                     │               [38;5;34m0[0m │ deberta[[38;5;34m0[0m][[38;5;34m0[0m]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ expand_dims ([38;5;33mLambda[0m)          │ ([38;5;34m1[0m, [38;5;34m768[0m)                  │               [38;5;34m0[0m │ slice_last[[38;5;34m0[0m][[38;5;34m0[0m]           │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ classification_mlp_0_128      │ ([38;5;34m1[0m, [38;5;34m128[0m)                  │          [38;5;34m98,432[0m │ expand_dims[[38;5;34m0[0m][[38;5;34m0[0m]          │
│ ([38;5;33mDense[0m)                       │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout ([38;5;33mDropout[0m)             │ ([38;5;34m1[0m, [38;5;34m128[0m)                  │               [38;5;34m0[0m │ classification_mlp_0_128[[38;5;34m…[0m │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ binary_classification_out     │ ([38;5;34m1[0m, [38;5;34m1[0m)                    │             [38;5;34m129[0m │ dropout[[38;5;34m0[0m][[38;5;34m0[0m]              │
│ ([38;5;33mDense[0m)                       │                           │                 │                            │
└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
[1m Total params: [0m[38;5;34m98,561[0m (385.00 KB)
[1m Trainable params: [0m[38;5;34m98,561[0m (385.00 KB)
[1m Non-trainable params: [0m[38;5;34m0[0m (0.00 B)
Building eval dataset...
Splitting dataset to featurewise...

Traceback (most recent call last):
  File "c:\Users\lapla\Downloads\FlowTransformer-master\FlowTransformer-master\main.py", line 88, in <module>
    (train_results, eval_results, final_epoch) = ft.evaluate(m, batch_size=128, epochs=5, steps_per_epoch=5, early_stopping_patience=5)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\lapla\Downloads\FlowTransformer-master\FlowTransformer-master\framework\flow_transformer.py", line 533, in evaluate
    eval_featurewise_X = samplewise_to_featurewise(eval_X)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\lapla\Downloads\FlowTransformer-master\FlowTransformer-master\framework\flow_transformer.py", line 502, in samplewise_to_featurewise
    input_ids_array = np.stack(input_ids_list).astype(np.int32)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: int() argument must be a string, a bytes-like object or a real number, not 'list'
[0m
